import re
import os
import argparse
from datetime import date
from pyspark.sql import SparkSession
from pyspark.sql.types import *
from pyspark.sql.functions import udf
from pyspark.sql.window import Window
from pyspark.sql.functions import *


class Adobe:

    def __inti__(self, src_path, today):
        self.src_path = src_path
        self.date = today
        self.target_path = src_path.split('.')[:-1] + '/' + 'SearchKeywordPerformance' + '/'
        self.target_filename = today + '_SearchKeywordPerformance.tab'

    # funtion to get the domain serach engin from the url
    def get_search_engine(self, url):
        m = re.search('http[s]?://[a-z]+\.([A-Za-z_0-9.-]+).*', url)
        return m.group(1)

    # function to get the serach keyword from the url
    def get_key_word(self, url):
        p = re.search('https?://[a-zA-Z0-9./?&=\-%]+(\?q=|\?p=|\&q=|\&p=)(?P<keyword>\w+\+?\w+).*', url)
        if p:
            return p.group('keyword')
        else:
            'None'


    # get the search engine and search key as a column in the dataframe
    def get_domain_search(self, raw_df, spark):
        windowSpec = Window.partitionBy("ip").orderBy(col("hit_time_gmt").asc())
        searchDf = raw_df.withColumn("row_number", row_number().over(windowSpec)).filter("row_number == 1")\
            .withColumn("search_engine_domain", self.get_search_engine_udf('referrer'))\
            .withColumn("search_keyword", self.get_key_word_udf('referrer'))\
            .select("ip","search_engine_domain", "search_keyword")
        return searchDf

    # derive the revenue generated by the search domain
    def get_revenue_df(self, raw_df , spark):
        return raw_df.filter("event_list == 1").select("ip", col("product_list").alias("pd_lst"), "event_list")

    # renaming the file from the destination
    def rename_file_name(self, target_path, target_filename):
        arr = os.listdir(target_path)

        for f in arr:
            if f.endswith(".csv"):
                name = target_path + f
        os.rename(name, target_filename + target_filename)


    # this is the main method and its called in the main
    def execute_main(self, src_path):

        # Initilization of Spark
        spark = SparkSession \
            .builder \
            .appName("Get revenvue per domain") \
            .getOrCreate()

        # reading raw data from the source path
        rawDf = spark.read.format("csv") \
            .option("header", "true") \
            .option("delimiter", "\t") \
            .option("inferSchema", "true") \
            .load(src_path)
        
        # registering the UDF
        get_search_engine_udf = udf(get_search_engine, StringType())
        get_key_word_udf = udf(get_key_word, StringType())

        searchDf = self.get_domain_search(rawDf, spark)
        revenueDf = self.get_revenue_df(rawDf, spark)
        joinedDf = searchDf.join(revenueDf, searchDf.ip == revenueDf.ip, "left").select(searchDf.ip,
                                                                                          searchDf.search_engine_domain,
                                                                                          searchDf.search_keyword,
                                                                                          revenueDf.pd_lst)

        finalRevDf = joinedDf.withColumn("revenue", split(joinedDf['pd_lst'], ';').getItem(3).cast(IntegerType())).drop(
            "pd_lst", "ip").na.fill(0)
        resultDf = finalRevDf.groupBy("search_engine_domain", "search_keyword").agg(
            sum("revenue").alias("Revenue")).orderBy(col("Revenue").desc())

        # writing the result dataframe as tab sepetated file
        resultDf.write.coalesce(1).options(header='True', delimiter='\t').csv(self.target_path)

        # calling the funtion to rename the file
        self.rename_file_name(self.target_path, self.target_filename)

if __name__=="__main__":

    # reading the source path as an argument
    parser = argparse.ArgumentParser(description='Argumant Parsing')
    parser.add_argument('--src_path', required=True, default='', metavar='<src_path>', help='source path')

    args = parser.parse_args()
    args_dict = vars(args)

    # Initialization of class and calling the main method
    kicker = Adobe(args_dict['src_path'],date.today())
    kicker.execute_main(args_dict['src_path'])
